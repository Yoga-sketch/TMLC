{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Twitter_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kiya tho refresh maarkefir comment karo</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>surat women perform yagna seeks divine grace f...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>this comes from cabinet which has scholars lik...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>with upcoming election india saga going import...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gandhi was gay does modi</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category\n",
       "0  when modi promised “minimum government maximum...      -1.0\n",
       "1  talk all the nonsense and continue all the dra...       0.0\n",
       "2  what did just say vote for modi  welcome bjp t...       1.0\n",
       "3  asking his supporters prefix chowkidar their n...       1.0\n",
       "4  answer who among these the most powerful world...       1.0\n",
       "5           kiya tho refresh maarkefir comment karo        0.0\n",
       "6  surat women perform yagna seeks divine grace f...       0.0\n",
       "7  this comes from cabinet which has scholars lik...       0.0\n",
       "8  with upcoming election india saga going import...       1.0\n",
       "9                         gandhi was gay does modi         1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    surat women perform yagna seeks divine grace f...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.index==6]['clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  0.,  1., nan])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 162980 entries, 0 to 162979\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   clean_text  162976 non-null  object \n",
      " 1   category    162973 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching Harvard dictionary to get positive and negative words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Entryword Source Pos Neg Pstv Affil Ngtv Hostile Strng Power Weak Subm Actv Psv Pleasure Pain Arousal EMOT Feel Virtue Vice Ovrst Undrst Acad Doctr Econ* Exch ECON Exprs Legal Milit Polit* POLIT Relig Role COLL Work Ritual Intrel Race Kin* MALE Female Nonadlt HU ANI PLACE Social Region Route Aquatic Land Sky Object Tool Food Vehicle Bldgpt Natobj Bodypt Comnobj Comform COM Say Need Goal Try Means Ach Persist Complt Fail Natpro Begin Vary Change Incr Decr Finish Stay Rise Move Exert Fetch Travel Fall Think Know Causal Ought Percv Comp Eval EVAL Solve Abs* ABS Qual Quan NUMB ORD CARD FREQ DIST Time* TIME Space POS DIM Dimn Rel COLOR Self Our You Name Yes No Negate Intrj IAV DAV SV IPadj IndAdj POWGAIN POWLOSS POWENDS POWAREN POWCON POWCOOP POWAPT POWPT POWDOCT POWAUTH POWOTH POWTOT RCTETH RCTREL RCTGAIN RCTLOSS RCTENDS RCTTOT RSPGAIN RSPLOSS RSPOTH RSPTOT AFFGAIN AFFLOSS AFFPT AFFOTH AFFTOT WLTPT WLTTRAN WLTOTH WLTTOT WLBGAIN WLBLOSS WLBPHYS WLBPSYC WLBPT WLBTOT ENLGAIN ENLLOSS ENLENDS ENLPT ENLOTH ENLTOT SKLAS SKLPT SKLOTH SKLTOT TRNGAIN TRNLOSS TRANS MEANS ENDS ARENAS PARTIC NATIONS AUD ANOMIE NEGAFF POSAFF SURE IF NOT TIMESP FOOD FORM Othertags Definition ',\n",
       " 'A H4Lvd DET ART  | article: Indefinite singular article--some or any one',\n",
       " 'ABANDON H4Lvd Neg Ngtv Weak Fail IAV AFFLOSS AFFTOT SUPV  |',\n",
       " 'ABANDONMENT H4 Neg Weak Fail Noun  |',\n",
       " 'ABATE H4Lvd Neg Psv Decr IAV TRANS SUPV  |',\n",
       " 'ABATEMENT Lvd Noun  ',\n",
       " 'ABDICATE H4 Neg Weak Subm Psv Finish IAV SUPV  |',\n",
       " 'ABHOR H4 Neg Hostile Psv Arousal SV SUPV  |',\n",
       " 'ABIDE H4 Pos Affil Actv Doctr IAV SUPV  |',\n",
       " 'ABIDE#1 Lvd Modif  ',\n",
       " 'ABIDE#2 Lvd SUPV  ',\n",
       " 'ABILITY Lvd MEANS Noun ABS ABS*  ',\n",
       " 'ABJECT H4 Neg Weak Subm Psv Vice IPadj Modif  |',\n",
       " 'ABLE H4Lvd Pos Pstv Strng Virtue EVAL MEANS Modif  | adjective: Having necessary power, skill, resources, etc.',\n",
       " 'ABNORMAL H4Lvd Neg Ngtv Vice NEGAFF Modif  |',\n",
       " 'ABOARD H4Lvd Space PREP LY  |',\n",
       " 'ABOLISH H4Lvd Neg Ngtv Hostile Strng Power Actv Intrel IAV POWOTH POWTOT SUPV  |',\n",
       " 'ABOLITION Lvd TRANS Noun  ',\n",
       " 'ABOMINABLE H4 Neg Strng Vice Ovrst Eval IndAdj Modif  |',\n",
       " 'ABORTIVE Lvd POWOTH POWTOT Modif POLIT  ']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('inqdict.txt')\n",
    "HIDict = f.read()\n",
    "HIDict = HIDict.splitlines()\n",
    "HIDict[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['equitable', 'popularity', 'solution', 'compassion', 'brotherly', 'suitable', 'rich', 'adhesive', 'glamorous', 'save', 'strut', 'baptism', 'eager', 'fearless', 'conducive', 'heartily', 'humor', 'sparkle', 'adjustable', 'candid']\n",
      "1647\n"
     ]
    }
   ],
   "source": [
    "poswords = [j for j in HIDict if \"Pos\" in j]  #using a list comprehension\n",
    "poswords = [j.split()[0] for j in poswords]\n",
    "poswords = [j.split(\"#\")[0] for j in poswords]\n",
    "poswords = set(poswords)\n",
    "poswords = [j.lower() for j in poswords]\n",
    "print(poswords[:20])\n",
    "print(len(poswords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rather', 'abhor', 'straggler', 'crumble', 'sprain', 'disclaim', 'envious', 'confess', 'severity', 'spite', 'noise', 'straggle', 'accost', 'resignation', 'avoid', 'meaningless', 'cross', 'shame', 'vagrant', 'conspiracy']\n",
      "2121\n"
     ]
    }
   ],
   "source": [
    "#Extract all the lines that contain the Neg tag\n",
    "negwords = [j for j in HIDict if \"Neg\" in j]  #using a list comprehension\n",
    "negwords = [j.split()[0] for j in negwords]\n",
    "negwords = [j.split(\"#\")[0] for j in negwords]\n",
    "negwords = set(negwords)\n",
    "negwords = [j.lower() for j in negwords]\n",
    "print(negwords[:20])\n",
    "print(len(negwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_text    4\n",
       "category      7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to fill the NA values in clean text column according to values present in category column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filling_na(df):\n",
    "    if pd.isna(df['clean_text']):\n",
    "        if df['category']==0.0:\n",
    "            df['clean_text']='neutral'\n",
    "        elif df['category']==1.0:\n",
    "            df['clean_text']='positive'\n",
    "        else:\n",
    "            df['clean_text']='negative'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.apply(filling_na, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130448</th>\n",
       "      <td>the foundation stone northeast gas grid inaugu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155642</th>\n",
       "      <td>dear terrorists you can run but you cant hide ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155698</th>\n",
       "      <td>offense the best defence with mission shakti m...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155770</th>\n",
       "      <td>have always heard politicians backing out thei...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158693</th>\n",
       "      <td>modi government plans felicitate the faceless ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159442</th>\n",
       "      <td>chidambaram gives praises modinomics</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160559</th>\n",
       "      <td>the reason why modi contested from seats 2014 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean_text  category\n",
       "130448  the foundation stone northeast gas grid inaugu...       NaN\n",
       "155642  dear terrorists you can run but you cant hide ...       NaN\n",
       "155698  offense the best defence with mission shakti m...       NaN\n",
       "155770  have always heard politicians backing out thei...       NaN\n",
       "158693  modi government plans felicitate the faceless ...       NaN\n",
       "159442               chidambaram gives praises modinomics       NaN\n",
       "160559  the reason why modi contested from seats 2014 ...       NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[pd.isna(df2['category'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the NLTK package for the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vignesh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/vignesh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to remove punctuation, numbers etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to remove Punctuations, Numbers and stop words \n",
    "\n",
    "import string\n",
    "def removePuncStr(s):\n",
    "    for c in string.punctuation:\n",
    "        s = s.replace(c,\" \")\n",
    "    return s\n",
    "\n",
    "def removePunc(text_array):\n",
    "    return [removePuncStr(h) for h in text_array]\n",
    "\n",
    "\n",
    "def removeNumbersStr(s):\n",
    "    for c in range(10):\n",
    "        n = str(c)\n",
    "        s = s.replace(n,\" \")\n",
    "    return s\n",
    "\n",
    "def removeNumbers(text_array):\n",
    "    return [removeNumbersStr(h) for h in text_array]\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def stopText(text_array):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stopped_text = []\n",
    "    for h in text_array:\n",
    "        words = word_tokenize(h)\n",
    "        h2 = ''\n",
    "        for w in words:\n",
    "            if w.lower() not in stop_words:\n",
    "                h2 = h2 + ' ' + w\n",
    "        stopped_text.append(h2)\n",
    "    return stopped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['clean_text2'] = df2.clean_text\n",
    "df2['clean_text2'] = removePunc(df2.clean_text)\n",
    "df2['clean_text2'] = removeNumbers(df2.clean_text)\n",
    "df2['clean_text2'] = stopText(df2.clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>modi promised “ minimum government maximum go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>talk nonsense continue drama vote modi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>say vote modi welcome bjp told rahul main cam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>asking supporters prefix chowkidar names modi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>answer among powerful world leader today trum...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category  \\\n",
       "0  when modi promised “minimum government maximum...      -1.0   \n",
       "1  talk all the nonsense and continue all the dra...       0.0   \n",
       "2  what did just say vote for modi  welcome bjp t...       1.0   \n",
       "3  asking his supporters prefix chowkidar their n...       1.0   \n",
       "4  answer who among these the most powerful world...       1.0   \n",
       "\n",
       "                                         clean_text2  \n",
       "0   modi promised “ minimum government maximum go...  \n",
       "1             talk nonsense continue drama vote modi  \n",
       "2   say vote modi welcome bjp told rahul main cam...  \n",
       "3   asking supporters prefix chowkidar names modi...  \n",
       "4   answer among powerful world leader today trum...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming the text to reduce it to its root form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To stem the text\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "def stemText(text_array):\n",
    "    stemmed_text = []\n",
    "    for h in text_array:\n",
    "        words = word_tokenize(h)\n",
    "        h2 = ''\n",
    "        for w in words:\n",
    "            h2 = h2 + ' ' + PorterStemmer().stem(w)\n",
    "        stemmed_text.append(h2)\n",
    "    return stemmed_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['clean_stemmed'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to convert the sentences into list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-2e524ca1e0c0>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2.clean_stemmed[i] = Convert(df2.clean_text2[i])\n",
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "def Convert(string):\n",
    "    li = list(string.split(\" \"))\n",
    "    return li\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    df2.clean_stemmed[i] = Convert(df2.clean_text2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "poswords = stemText(poswords)\n",
    "negwords = stemText(negwords)\n",
    "\n",
    "for i in range(len(poswords)):\n",
    "    poswords[i] = poswords[i].strip(\" \")\n",
    "\n",
    "for i in range(len(negwords)):\n",
    "    negwords[i] = negwords[i].strip(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the number of positive and negative words in each stemmed collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-c39d396efe1c>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Pos_words'][i] = len(set(df2.clean_stemmed[i]).intersection(set(poswords)))\n",
      "<ipython-input-24-c39d396efe1c>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Neg_words'][i] = len(set(df2.clean_stemmed[i]).intersection(set(negwords)))\n"
     ]
    }
   ],
   "source": [
    "df2['Pos_words'] = 0\n",
    "df2['Neg_words'] = 0\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    df2['Pos_words'][i] = len(set(df2.clean_stemmed[i]).intersection(set(poswords)))\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df2['Neg_words'][i] = len(set(df2.clean_stemmed[i]).intersection(set(negwords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_text2</th>\n",
       "      <th>clean_stemmed</th>\n",
       "      <th>Pos_words</th>\n",
       "      <th>Neg_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>modi promised “ minimum government maximum go...</td>\n",
       "      <td>[, modi, promised, “, minimum, government, max...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>talk nonsense continue drama vote modi</td>\n",
       "      <td>[, talk, nonsense, continue, drama, vote, modi]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>say vote modi welcome bjp told rahul main cam...</td>\n",
       "      <td>[, say, vote, modi, welcome, bjp, told, rahul,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>asking supporters prefix chowkidar names modi...</td>\n",
       "      <td>[, asking, supporters, prefix, chowkidar, name...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>answer among powerful world leader today trum...</td>\n",
       "      <td>[, answer, among, powerful, world, leader, tod...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category  \\\n",
       "0  when modi promised “minimum government maximum...      -1.0   \n",
       "1  talk all the nonsense and continue all the dra...       0.0   \n",
       "2  what did just say vote for modi  welcome bjp t...       1.0   \n",
       "3  asking his supporters prefix chowkidar their n...       1.0   \n",
       "4  answer who among these the most powerful world...       1.0   \n",
       "\n",
       "                                         clean_text2  \\\n",
       "0   modi promised “ minimum government maximum go...   \n",
       "1             talk nonsense continue drama vote modi   \n",
       "2   say vote modi welcome bjp told rahul main cam...   \n",
       "3   asking supporters prefix chowkidar names modi...   \n",
       "4   answer among powerful world leader today trum...   \n",
       "\n",
       "                                       clean_stemmed  Pos_words  Neg_words  \n",
       "0  [, modi, promised, “, minimum, government, max...          1          3  \n",
       "1    [, talk, nonsense, continue, drama, vote, modi]          0          0  \n",
       "2  [, say, vote, modi, welcome, bjp, told, rahul,...          2          0  \n",
       "3  [, asking, supporters, prefix, chowkidar, name...          2          1  \n",
       "4  [, answer, among, powerful, world, leader, tod...          0          0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(columns=['clean_text','clean_text2'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>clean_stemmed</th>\n",
       "      <th>Pos_words</th>\n",
       "      <th>Neg_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>[, modi, promised, “, minimum, government, max...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[, talk, nonsense, continue, drama, vote, modi]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[, say, vote, modi, welcome, bjp, told, rahul,...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[, asking, supporters, prefix, chowkidar, name...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[, answer, among, powerful, world, leader, tod...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                      clean_stemmed  Pos_words  \\\n",
       "0      -1.0  [, modi, promised, “, minimum, government, max...          1   \n",
       "1       0.0    [, talk, nonsense, continue, drama, vote, modi]          0   \n",
       "2       1.0  [, say, vote, modi, welcome, bjp, told, rahul,...          2   \n",
       "3       1.0  [, asking, supporters, prefix, chowkidar, name...          2   \n",
       "4       1.0  [, answer, among, powerful, world, leader, tod...          0   \n",
       "\n",
       "   Neg_words  \n",
       "0          3  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(columns='clean_stemmed', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are 7 records having NaN values in category. These are seperated to form the test data using model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=df2[df2.category.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2[~pd.isnull(df2['category'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using number of positive and negative words as the only columns for predicting category as we want numerical values in columns . These two columns are derived from clean text column.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>Pos_words</th>\n",
       "      <th>Neg_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162975</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162976</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162977</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162978</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162979</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162973 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        category  Pos_words  Neg_words\n",
       "0           -1.0          1          3\n",
       "1            0.0          0          0\n",
       "2            1.0          2          0\n",
       "3            1.0          2          1\n",
       "4            1.0          0          0\n",
       "...          ...        ...        ...\n",
       "162975      -1.0          0          2\n",
       "162976      -1.0          1          2\n",
       "162977       0.0          0          0\n",
       "162978       0.0          0          0\n",
       "162979       1.0          3          2\n",
       "\n",
       "[162973 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into train and test in 80: 20 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split \n",
    "from sklearn.model_selection import train_test_split\n",
    "X1 = df2.drop(['category'],axis=1)\n",
    "Y1 = df2.category\n",
    "\n",
    "\n",
    "\n",
    "X1_train, X1_test, Y1_train, Y1_test = train_test_split(X1,Y1,test_size=0.2,random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X1_train_scaled = scaler.fit_transform(X1_train)\n",
    "X1_test_scaled = scaler.transform(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 s, sys: 249 ms, total: 10.8 s\n",
      "Wall time: 10.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=7, n_estimators=500, random_state=3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model1 = RandomForestClassifier(n_estimators=500, max_depth=7, random_state=3)\n",
    "model1.fit(X1_train_scaled,Y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32595,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1_pred = model1.predict(X1_test_scaled)\n",
    "Y1_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5499923301119803"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(Y1_pred, Y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1=df_test.drop(columns='category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the test values where category values were NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.predict(df_test1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
